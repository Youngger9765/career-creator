name: Deploy Backend to Cloud Run

on:
  push:
    branches:
      - main        # Deploy to production
      - staging     # Deploy to staging
    paths:
      - 'backend/**'
      - '.github/workflows/deploy-backend.yaml'

  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

env:
  PROJECT_ID: career-creator-card
  REGION: asia-east1

jobs:
  deploy:
    runs-on: ubuntu-latest
    if: github.ref_name == 'staging' || github.ref_name == 'main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set environment variables based on branch
        run: |
          if [ "${{ github.ref_name }}" = "staging" ]; then
            echo "ENVIRONMENT=staging" >> $GITHUB_ENV
            echo "SERVICE_NAME=career-creator-backend-staging" >> $GITHUB_ENV
            # Use transaction pooler (port 6543) for better concurrency (200+ connections)
            # Convert :5432 to :6543 in DATABASE_POOLER_URL
            DATABASE_URL_FIXED=$(echo "${{ secrets.DATABASE_POOLER_URL_STAGING }}" | sed 's/:5432/:6543/g')
            echo "DATABASE_URL=$DATABASE_URL_FIXED" >> $GITHUB_ENV
            echo "DATABASE_POOLER_URL=${{ secrets.DATABASE_POOLER_URL_STAGING }}" >> $GITHUB_ENV
            echo "JWT_SECRET=${{ secrets.JWT_SECRET_STAGING }}" >> $GITHUB_ENV
            echo "SUPABASE_URL=${{ secrets.SUPABASE_URL_STAGING }}" >> $GITHUB_ENV
            echo "SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY_STAGING }}" >> $GITHUB_ENV
            echo "GCS_BUCKET_NAME=${{ secrets.GCS_BUCKET_NAME_STAGING }}" >> $GITHUB_ENV
            echo "USE_MOCK_STORAGE=${{ secrets.USE_MOCK_STORAGE_STAGING }}" >> $GITHUB_ENV
          elif [ "${{ github.ref_name }}" = "main" ]; then
            echo "ENVIRONMENT=production" >> $GITHUB_ENV
            echo "SERVICE_NAME=career-creator-backend-production" >> $GITHUB_ENV
            # Use transaction pooler (port 6543) for better concurrency (200+ connections)
            # Convert :5432 to :6543 in DATABASE_POOLER_URL
            DATABASE_URL_FIXED=$(echo "${{ secrets.DATABASE_POOLER_URL_PRODUCTION }}" | sed 's/:5432/:6543/g')
            echo "DATABASE_URL=$DATABASE_URL_FIXED" >> $GITHUB_ENV
            echo "DATABASE_POOLER_URL=${{ secrets.DATABASE_POOLER_URL_PRODUCTION }}" >> $GITHUB_ENV
            echo "JWT_SECRET=${{ secrets.JWT_SECRET_PRODUCTION }}" >> $GITHUB_ENV
            echo "SUPABASE_URL=${{ secrets.SUPABASE_URL_PRODUCTION }}" >> $GITHUB_ENV
            echo "SUPABASE_ANON_KEY=${{ secrets.SUPABASE_ANON_KEY_PRODUCTION }}" >> $GITHUB_ENV
            echo "GCS_BUCKET_NAME=${{ secrets.GCS_BUCKET_NAME_PRODUCTION }}" >> $GITHUB_ENV
            echo "USE_MOCK_STORAGE=${{ secrets.USE_MOCK_STORAGE_PRODUCTION }}" >> $GITHUB_ENV
            echo "TEMP_INIT_SECRET=${{ secrets.TEMP_INIT_SECRET_PRODUCTION }}" >> $GITHUB_ENV
          fi
          echo "IMAGE_TAG=gcr.io/${{ env.PROJECT_ID }}/career-creator-backend:${{ github.ref_name }}-${{ github.sha }}" >> $GITHUB_ENV

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          project_id: ${{ env.PROJECT_ID }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - name: Configure Docker for GCR
        run: gcloud auth configure-docker gcr.io

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: backend
          file: backend/Dockerfile
          push: true
          tags: ${{ env.IMAGE_TAG }}
          cache-from: type=registry,ref=gcr.io/${{ env.PROJECT_ID }}/career-creator-backend:${{ github.ref_name }}-cache
          cache-to: type=registry,ref=gcr.io/${{ env.PROJECT_ID }}/career-creator-backend:${{ github.ref_name }}-cache,mode=max

      - name: Deploy to Cloud Run
        run: |
          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image ${{ env.IMAGE_TAG }} \
            --platform managed \
            --region ${{ env.REGION }} \
            --allow-unauthenticated \
            --port 8000 \
            --memory 1Gi \
            --cpu 1 \
            --concurrency 100 \
            --min-instances 0 \
            --max-instances 10 \
            --set-env-vars DATABASE_URL="${{ env.DATABASE_URL }}",DIRECT_DATABASE_URL="${{ env.DIRECT_DATABASE_URL }}",JWT_SECRET="${{ env.JWT_SECRET }}",JWT_ALGORITHM=HS256,ACCESS_TOKEN_EXPIRE_MINUTES=15,REFRESH_TOKEN_EXPIRE_DAYS=7,ENVIRONMENT="${{ env.ENVIRONMENT }}",SUPABASE_URL="${{ env.SUPABASE_URL }}",SUPABASE_ANON_KEY="${{ env.SUPABASE_ANON_KEY }}",GCS_BUCKET_NAME="${{ env.GCS_BUCKET_NAME }}",USE_MOCK_STORAGE="${{ env.USE_MOCK_STORAGE }}",TEMP_INIT_SECRET="${{ env.TEMP_INIT_SECRET }}" \
            --timeout 300s \
            --project ${{ env.PROJECT_ID }}

      - name: Get service URL
        id: get-url
        run: |
          SERVICE_URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} \
            --region=${{ env.REGION }} \
            --project=${{ env.PROJECT_ID }} \
            --format="value(status.url)")
          echo "SERVICE_URL=$SERVICE_URL" >> $GITHUB_OUTPUT
          echo "üåê Backend deployed to: $SERVICE_URL"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: backend/requirements.txt

      - name: Install Python dependencies
        run: pip install -r backend/requirements.txt

      - name: Run database migrations
        run: |
          echo "Running migrations on ${{ env.ENVIRONMENT }} database..."

          # Use transaction pooler (port 6543) - supports more concurrent connections
          # Session pooler (port 5432) has MaxClientsInSessionMode limit (~15 connections)
          export DATABASE_URL=$(echo "${{ env.DATABASE_POOLER_URL }}" | sed 's/:5432/:6543/g')

          # Debug: Show connection details (mask password)
          echo "üîç DEBUG: Database connection info:"
          echo "  - Full URL (masked): $(echo $DATABASE_URL | sed 's/:\/\/[^:]*:[^@]*@/:\/\/***:***@/')"
          echo "  - Hostname: $(echo $DATABASE_URL | grep -oP '(?<=@)[^:/]+' || echo 'Could not extract')"
          echo "  - Port: $(echo $DATABASE_URL | grep -oP '(?<=:)[0-9]+(?=/)' || echo 'Could not extract')"
          echo "  - Database: $(echo $DATABASE_URL | grep -oP '(?<=/)[^?]+' || echo 'Could not extract')"

          # Check if using transaction pooler (port 6543) for better concurrency
          if echo "$DATABASE_URL" | grep -q "pooler.supabase.com:6543"; then
            echo "‚úÖ Using transaction pooler (supports more concurrent connections)"
          else
            echo "‚ö†Ô∏è  WARNING: Not using expected transaction pooler URL!"
          fi

          # Navigate to backend directory and run migrations
          cd backend
          alembic upgrade head

          echo "‚úÖ Migrations completed successfully"

      - name: Seed demo users
        run: |
          echo "Seeding demo user accounts..."
          # Use transaction pooler (port 6543) for better concurrency
          export DATABASE_URL=$(echo "${{ env.DATABASE_POOLER_URL }}" | sed 's/:5432/:6543/g')
          cd backend
          python -c "from app.core.seeds import seed_demo_users; seed_demo_users()"
          echo "‚úÖ Demo users seeded successfully"

      - name: Rehash test user passwords
        if: env.ENVIRONMENT == 'staging'
        run: |
          echo "Rehashing test user passwords with bcrypt 10 rounds..."
          export DATABASE_URL=$(echo "${{ env.DATABASE_POOLER_URL }}" | sed 's/:5432/:6543/g')
          cd backend
          python rehash_passwords.py
          echo "‚úÖ Test users rehashed successfully"

      - name: Run health check
        run: |
          echo "Waiting for service to be ready..."
          MAX_ATTEMPTS=10
          ATTEMPT=0
          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            ATTEMPT=$((ATTEMPT+1))
            echo "Attempt $ATTEMPT/$MAX_ATTEMPTS..."
            if curl -f -s ${{ steps.get-url.outputs.SERVICE_URL }}/health > /dev/null 2>&1; then
              echo "‚úÖ Health check passed"
              exit 0
            fi
            sleep 5
          done
          echo "‚ùå Health check failed after $MAX_ATTEMPTS attempts"
          exit 1

      - name: Clean up old images
        if: success()
        continue-on-error: true
        run: |
          echo "üßπ Cleaning up old backend images..."
          # Keep only the latest 3 images for each environment
          IMAGE_NAME="gcr.io/${{ env.PROJECT_ID }}/career-creator-backend"

          # Get all digests for the current environment tag pattern
          DIGESTS=$(gcloud container images list-tags $IMAGE_NAME \
            --filter="tags:${{ github.ref_name }}-*" \
            --format="get(digest)" \
            --sort-by="~timestamp" | tail -n +4)

          # Delete old images
          if [ ! -z "$DIGESTS" ]; then
            for DIGEST in $DIGESTS; do
              echo "Deleting old image: $IMAGE_NAME@$DIGEST"
              gcloud container images delete "$IMAGE_NAME@$DIGEST" --quiet --force-delete-tags || true
            done
            echo "‚úÖ Old backend images cleaned up"
          else
            echo "No old backend images to clean up"
          fi

      - name: Notify deployment success
        if: success()
        run: |
          echo "üöÄ Successfully deployed backend to ${{ env.ENVIRONMENT }} environment"
          echo "üì± Backend URL: ${{ steps.get-url.outputs.SERVICE_URL }}"
          echo "üîß Environment: ${{ env.ENVIRONMENT }}"
          echo "üì¶ Image: ${{ env.IMAGE_TAG }}"
